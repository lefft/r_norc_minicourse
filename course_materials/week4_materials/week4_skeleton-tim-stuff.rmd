---
title: "example R markdown document"
subtitle: "(created by modifying `week4_skeleton.rmd`)"
author: "june9/2017, R mini-course at NORC-ARC"
date: "tim leffel"
output: html_document
---

## 1. setting things up

### 1.1 set global chunk options and load packages

```{r setup, include=FALSE}
# echo=TRUE: the code you type in a chunk will appear in the output
knitr::opts_chunk$set(echo=TRUE) 
```

We'll end up using functions from the following packages:

```{r attach_packages, message=FALSE, warning=FALSE}
library("dplyr"); library("reshape2"); library("ggplot2");
library("ggthemes"); library("knitr");

# also set the ggplot2 theme to something nicer than the default
theme_set(theme_fivethirtyeight(base_size=20))
```


### 1.2 describe and read in dataset, and inspect

Here we read in a dataset from a url and inspect the first few rows. For 5000 English words, this dataset lists the word's frequency (number of occurrences) in the Corpus of Contemporary American English (COCA) in `dat$Frequency`; specifies what kind of word it is (e.g. noun or verb or article) in `dat$PartOfSpeech`; and also includes the word's frequency *rank*, i.e. what position it would be at if you ordered all words in the list by their corpus frequency. These are the three columns we'll look at here. 

```{r}
# using two lines so the url doesn't overflow 
# (maximum of 80 characters per line of code is a nice cutoff point)
link <- paste0("http://lefft.xyz/r_minicourse/",
               "datasets/top5k-word-frequency-dot-info.csv")

dat <- read.csv(link, stringsAsFactors=FALSE)

head(dat, n=5)
```

### 1.3 clean up dataset as desired

Let's change the column names just for demo purposes:

```{r}
names(dat) <- c("rank","word","part_of_speech","frequency","dispersion")
```

And then let's recode part of speech so that we can look at it and understand what it means...

```{r}
# see what the unique vals of `part_of_speech` are
unique(dat$part_of_speech)
```

But there's a problem: we don't know the corresepondence between the part of speech tags and what they stand for! We can get a hint by using the following (**google `sapply()` -- extremely useful** -- it basically does the same kind of work that a `for`-loop would do)

```{r}
# see a few examples of each 
sapply(unique(dat$part_of_speech), function(x){
  paste0(x, " ", dat$word[dat$part_of_speech==x][1:3])
})
```

Now we can recode it with a named vector as a "lookup table", as we have in similar cases in the past:
```{r}
# set the "key-value" pairs
pos_lkup <- c(
  a="article", v="verb", c="conjunction/coordinator", i="preposition",
  t="infinitive 'to'", p="pronoun", d="determiner", x="negation", r="adverb",
  m="number (cardinal/ordinal/etc.)", n="noun", e="expletive 'there'", 
  j="adjective", u="particle"
)

# reassign `$part_of_speech` to the clean values, matching by the current ones
dat$part_of_speech <- 
  as.character(pos_lkup[match(dat$part_of_speech, names(pos_lkup))])
```


Ahhh, much better:

```{r}
kable(head(dat, n=5))
```


## 2. summarize and visualize columns of interest

Let's look at the relationship between `dat$frequency` and `dat$rank`, for each part of speech. (yayy, five thirty eight theme via `ggthemes::`!)

```{r}
# distribution of pos's
table(dat$part_of_speech, useNA="ifany")
```

To simplify things, let's just look at nouns, verbs, adjectives, and adverbs.

```{r}
# **this can be done equivalently a number of ways -- what are some others?**
dat <- subset(dat, part_of_speech %in% c("noun","verb","adjective","adverb"))
```

### 2.1 display some summary tables

Here's the distribution of part of speech in the simplified dataset:

```{r}
# add some stuff to the `table` command above to make a formatted version
kable(as.data.frame(table(dat$part_of_speech, useNA="ifany")),
      col.names=c("part of speech", "count (number of rows of `dat`)"))
```

And a table for frequency and rank by part of speech:

```{r}
# use `aggregate()` to get group-wise means
freq_tab <- aggregate(frequency ~ part_of_speech, data=dat, FUN="mean")
rank_tab <- aggregate(rank ~ part_of_speech, data=dat, FUN="mean")

# join the two aggregated df's with `dplyr::left_join()`
both_tab <- left_join(freq_tab, rank_tab, by="part_of_speech")

# now display the table
kable(both_tab, 
      col.names=c("part of speech", "mean corpus freq.", "mean freq. rank"),
      align=c("c","l","l"), digits=0)
```


### 2.2 display some plots

Here's plots of the distributions of frequency and rank, broken down by part of speech: 

```{r plotz, fig.width=9, fig.height=6, out.width='48%', fig.show="hold"}
# distribution of frequency by part of speech
ggplot(dat, aes(x=part_of_speech, y=frequency)) +
  geom_boxplot() + 
  scale_y_log10() +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="log word frequency by part of speech",
       subtitle="for 5000 most frequent words in COCA")

# distribution of rank by part of speech
ggplot(dat, aes(x=part_of_speech, y=rank)) +
  geom_boxplot() + 
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1)) +
  labs(title="frequency rank by part of speech",
       subtitle="for 5000 most frequent words in COCA")
```

**note**: here's the corresponding commands to create these plots with base graphics (this chunk is not evaluated because of the chunk option `eval=FALSE`; but it is displayed because we set `echo=TRUE` in the setup chunk):

```{r base_plotz, eval=FALSE}
# same as above plots, but with base graphics
boxplot(frequency ~ part_of_speech, data=dat)
boxplot(rank ~ part_of_speech, data=dat)
```

It often makes sense to perform a log transformation on frequency data, so let's add two new columns for the log of frequency and of rank. (note we secretly did this in the first plot above, with `scale_y_log10()`)

```{r}
dat$log_rank <- log(dat$rank)
dat$log_freq <- log(dat$frequency)
```


And here is a visual exemplification of [**Zipf's Law**](https://en.wikipedia.org/wiki/Zipf%27s_law#Motivation): corpus frequency is inversely proportional to frequency rank in the same corpus!

```{r zipf_plot, fig.width=9, fig.height=5, out.width='95%', fig.align="center"}
# peep another theme
theme_set(theme_minimal(base_size=16))

ggplot(dat, aes(x=log_rank, y=log_freq)) +
  geom_point(shape=1, size=1) +
  facet_wrap(~part_of_speech, nrow=1) +
  labs(x="log frequency rank", y="log corpus frequency",
       title="an illustration of Zipf's Law",
       subtitle="source: Corpus of Contemporary American English (COCA)") +
  theme(plot.subtitle=element_text(size=12, face="italic"))
```


## 3. perform some analysis (if desired)

Here we can use statistical models to assess the relationship between different columns of our dataset. 

### 3.1 fit a model to the data 

```{r}
# fit a linear regression model with `lm()` 
# the outcome is before the tilde; and 
# the predictors are after the tilde, separated by "+"
mod <- lm(log_rank ~ log_freq + part_of_speech, data=dat)
```

### 3.2 examine the model summary and evaluate relationships

```{r}
# look at the full model summary
summary(mod)
```

The coefficient table gives us most of what we need to know.

```{r}
# print a table of coefficient estimates with se's and t and p-values
kable(summary(mod)$coef, digits=4)
```

### 3.3 evaluate the overall quality of the model fit 

R-squared is bounded by $[0, 1]$, so this fit is basically perfect.

```{r}
# extract the r-squared value from the model summary
summary(mod)$r.squared

# or compute it directly (see week1 notes for pearson's r)
cor(dat$log_rank, fitted(mod))^2

# **exercise**: compute the root-mean-square-error for this model
# **question**: does it provide any information that r^2 doesn't in this case?
```


### 3.4 summarize the findings

Looks like corpus frequency is inversely proportional to frequency rank! And part of speech seems to matter for rank, too. But is there an interaction between the effect of corpus frequency on rank and the effect of part of speech on rank?! To find out, try substituting `*` (times) for `+` (plus) in the `lm()` command. This will include the interaction terms for `log_freq` and `part_of_speech` as predictors in the model.

Okay done now! Woop woop ~~ :p




